{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install factor_analyzer\n",
    "# !pip install https://github.com/pandas-profiling/pandas-profiling/archive/master.zip\n",
    "# conda install -c conda-forge scikit-learn-extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "import sklearn.datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "from pandas_profiling import ProfileReport\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from operator import itemgetter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Creation\n",
    "The primary dataframe we will be working with is df_fct, which is a dataframe composed of only the 36 factor variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe from customer_data file\n",
    "df = pd.read_csv('customer_data.csv')\n",
    "\n",
    "# Create dataframe of factors only\n",
    "df_fct =  df.drop(['UID','Const'], axis=1)\n",
    "\n",
    "# Number of variables/factors/stimuli\n",
    "variables_to_examine = len(df_fct.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factor Analysis\n",
    "\n",
    "The variables are all on a similar scale, so we will use the covariance matrix for identifying principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create factor analysis object and perform factor analysis\n",
    "fa = FactorAnalyzer(n_factors=variables_to_examine, rotation=None)\n",
    "fa.fit(df_fct)\n",
    "\n",
    "# Check Eigenvalues\n",
    "ev, v = fa.get_eigenvalues()\n",
    "\n",
    "# Create FactorAnalyzer object\n",
    "n_factors = sum(i >= 1 for i in ev)\n",
    "fa = FactorAnalyzer(n_factors=n_factors, rotation=None)\n",
    "\n",
    "# Fit factor analysis model to variables\n",
    "fa.fit(df_fct)\n",
    "\n",
    "# Scores for the factor analysis, converted to dataframe\n",
    "scores = pd.DataFrame(fa.transform(df_fct))\n",
    "\n",
    "\n",
    "##############\n",
    "# Extra Stuff\n",
    "##############\n",
    "\n",
    "# The loadings are the coefficients that make up the linear combination of original variables to get the factors (v1 = l1x1 + l2X2)\n",
    "loadings = fa.loadings_\n",
    "\n",
    "# Create dataframe of eigenvalues of the covariance matrix\n",
    "\n",
    "data = {'factor'                    : range(1,n_factors+1),\n",
    "        'eigenvalues'               : fa.get_eigenvalues()[0][0:n_factors],\n",
    "        'common_factor_eigenvalues' : fa.get_eigenvalues()[1][0:n_factors],\n",
    "        'variance'                  : fa.get_factor_variance()[0],\n",
    "        'proportional_variance'     : fa.get_factor_variance()[1],\n",
    "        'cumulative_variance'       : fa.get_factor_variance()[2]\n",
    "       }\n",
    "\n",
    "cov_matrix_eigenvals = pd.DataFrame(data=data).set_index('factor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw=[]\n",
    "\n",
    "for i in range(2,7):\n",
    "    \n",
    "    # Create clustering objects\n",
    "    cls1 = KMeans(n_clusters=i, random_state=0)\n",
    "    cls2 = KMedoids(n_clusters=i, random_state=0)\n",
    "    cls3 = AgglomerativeClustering(n_clusters=i, affinity = 'euclidean', linkage ='ward') #if linkage is ward, affinity must be Euclidean\n",
    "    cls_algs = [['kMeans', cls1], ['kMedoids', cls2], ['Hierarchical', cls3]]\n",
    "    \n",
    "    # Fit and score clustering solutions for i clusters with each clustering algorithm\n",
    "    for cls in cls_algs:\n",
    "        \n",
    "        # Fit the model to the factor analysis scores\n",
    "        cls[1].fit(scores)\n",
    "        \n",
    "        # List of assigned clusters\n",
    "        clusters = cls[1].fit_predict(scores)\n",
    "        \n",
    "        # Silhouette scores for each solution\n",
    "        silhouette_avg = silhouette_score(scores,clusters)\n",
    "        \n",
    "        # Store solution info [algorithm, number of clusters, avg silhouette score, cluster predictions]\n",
    "        i_stats = [cls[0], i, silhouette_avg, clusters]\n",
    "        sw.append(i_stats)\n",
    "        \n",
    "        # Add columns of cluster assignments to df_fct datafram\n",
    "        df_fct[algorithm+'_'+'cluster'+'_'+str(i)] = clusters\n",
    "\n",
    "\n",
    "# Reorder cluster lists by descending silhouette scores.  Clusters in first element should be assigned to training data.\n",
    "sw = sorted(sw, key=itemgetter(2), reverse=True)\n",
    "\n",
    "# Add the labels to the training dataset (you can ignore the warning when the cell runs)\n",
    "df_fct['cluster'] = sw[0][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "\n",
    "#### Split into training, validation, and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the variable columns and the optimal cluster assignment\n",
    "data_of_interest = df_fct.iloc[:,np.r_[:variables_to_examine,-1]]\n",
    "\n",
    "# Split data into 75% training, 12.5% validation, 12.5% test\n",
    "train, valid = train_test_split(data_of_interest, test_size=0.25, random_state=123)\n",
    "\n",
    "valid, test = train_test_split(valid, test_size=0.5, random_state=123)\n",
    "\n",
    "# X is unlabeled training data, y is true training labels \n",
    "X, y = train.loc[:, train.columns != 'cluster'], train['cluster']\n",
    "\n",
    "X_valid, y_valid = valid.loc[:, train.columns != 'cluster'], valid['cluster']\n",
    "\n",
    "X_test, y_test = test.loc[:, test.columns != 'cluster'], test['cluster']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_scores = []\n",
    "\n",
    "clf1 = RandomForestClassifier(random_state=0)\n",
    "clf2 = GradientBoostingClassifier(random_state=0)\n",
    "clf3 = SVC(random_state=0)\n",
    "clf4 = KNeighborsClassifier()\n",
    "\n",
    "classifiers = [['rf', clf1], ['gbt', clf2], ['svc', clf3], ['knn', clf4]]\n",
    "\n",
    "for classifier in classifiers:\n",
    "    \n",
    "    # Fit classifier to training data\n",
    "    classifier[1].fit(X,y)    \n",
    "    \n",
    "    # Store classifier-specific results [algorithm object, classifier name, scores]\n",
    "    results = [classifier[1], classifier[0], classifier[1].score(X_valid,y_valid)]\n",
    "\n",
    "    # Overall classifier results\n",
    "    clf_scores.append(results)\n",
    "\n",
    "# Sort classifier accuracy in descending order\n",
    "clf_scores = sorted(clf_scores, key=itemgetter(1), reverse=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### View feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable\n",
      "4     0.242242\n",
      "31    0.080437\n",
      "6     0.054669\n",
      "2     0.047890\n",
      "1     0.041253\n",
      "5     0.040327\n",
      "12    0.035441\n",
      "9     0.030601\n",
      "33    0.028794\n",
      "26    0.025740\n",
      "Name: avg, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# This should probably be a function that is nested within the classifier function\n",
    "\n",
    "importance = pd.DataFrame({'variable': list(range(1,37)),\n",
    "                           'rf': clf1.feature_importances_,\n",
    "                           'gbt': clf2.feature_importances_,\n",
    "                           'avg': (importance['rf']+importance['gbt'])/2},\n",
    "                         ).set_index('variable')\n",
    "\n",
    "# View top 10 variables when RF and GBT models are averaged\n",
    "top_10_avg = importance.sort_values(by='avg', ascending=False)['avg'].head(10)\n",
    "\n",
    "print(top_10_avg)\n",
    "\n",
    "# 7 out of 10 of the top variables appear in both lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='variable'>"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visual representation of the average importance of the difference variables\n",
    "importance.sort_values(by='avg', ascending=False)['avg'].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing final accuracy of model with selected best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data: 90.566% accuracy\n",
      "Binary variables: 73.585% accuracy\n"
     ]
    }
   ],
   "source": [
    "# Changes dataset into 0s and 1s depending on the value of the cell\n",
    "X_test_zero_one = X_test.mask(data_of_interest > 0, 1).mask(data_of_interest <= 0, 0)\n",
    "\n",
    "# Raw data accuracy = 0.9056603773584906\n",
    "print(f'Raw data: {round(clf_scores[0][0].score(X_test,y_test),5)*100}% accuracy')\n",
    "\n",
    "# Binary variables accuracy = 0.7358490566037735\n",
    "print(f'Binary variables: {round(clf_scores[0][0].score(X_test_zero_one,y_test),5)*100}% accuracy')\n",
    "\n",
    "# That seems like a pretty significant difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        42\n",
      "           1       0.75      0.82      0.78        11\n",
      "\n",
      "    accuracy                           0.91        53\n",
      "   macro avg       0.85      0.87      0.86        53\n",
      "weighted avg       0.91      0.91      0.91        53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# I don't think the necessarily needs to be in the final product, but it helps evaluate the models.\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "valid_pred = clf3.predict(X_valid)\n",
    "\n",
    "print(classification_report(y_valid, valid_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
